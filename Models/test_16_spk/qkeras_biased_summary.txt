Model: "sequential_1"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 normalization_1 (Normalizat  (6191, 171, 13, 1)       3         
 ion)                                                            
                                                                 
 conv2d_1 (QConv2D)          (6191, 171, 13, 16)       160       
                                                                 
 batch_normalization_4 (Batc  (6191, 171, 13, 16)      64        
 hNormalization)                                                 
                                                                 
 act_1 (QActivation)         (6191, 171, 13, 16)       0         
                                                                 
 conv2d_2 (QConv2D)          (6191, 86, 7, 32)         4640      
                                                                 
 batch_normalization_5 (Batc  (6191, 86, 7, 32)        128       
 hNormalization)                                                 
                                                                 
 act_2 (QActivation)         (6191, 86, 7, 32)         0         
                                                                 
 max_pooling2d_2 (MaxPooling  (6191, 43, 3, 32)        0         
 2D)                                                             
                                                                 
 conv2d_3 (QConv2D)          (6191, 22, 2, 64)         18496     
                                                                 
 batch_normalization_6 (Batc  (6191, 22, 2, 64)        256       
 hNormalization)                                                 
                                                                 
 act_3 (QActivation)         (6191, 22, 2, 64)         0         
                                                                 
 max_pooling2d_3 (MaxPooling  (6191, 11, 1, 64)        0         
 2D)                                                             
                                                                 
 conv2d_4 (QConv2D)          (6191, 6, 1, 128)         73856     
                                                                 
 batch_normalization_7 (Batc  (6191, 6, 1, 128)        512       
 hNormalization)                                                 
                                                                 
 act_4 (QActivation)         (6191, 6, 1, 128)         0         
                                                                 
 global_average_pooling2d_1   (6191, 128)              0         
 (GlobalAveragePooling2D)                                        
                                                                 
 flatten_1 (Flatten)         (6191, 128)               0         
                                                                 
 dense_1 (QDense)            (6191, 32)                4128      
                                                                 
 act_5 (QActivation)         (6191, 32)                0         
                                                                 
 dense_2 (QDense)            (6191, 16)                528       
                                                                 
 softmax (Activation)        (6191, 16)                0         
                                                                 
=================================================================
Total params: 102,771
Trainable params: 102,288
Non-trainable params: 483
_________________________________________________________________

Number of operations in model:
    conv2d_1                      : 320112 (smult_8_8)
    conv2d_2                      : 2774016 (smux_1_2)
    conv2d_3                      : 811008 (smult_8_2)
    conv2d_4                      : 442368 (smult_8_2)
    dense_1                       : 4096  (smux_1_2)
    dense_2                       : 512   (smux_1_2)

Number of operation types in model:
    smult_8_2                     : 1253376
    smult_8_8                     : 320112
    smux_1_2                      : 2778624

Weight profiling:
    conv2d_1_weights               : 144   (8-bit unit)
    conv2d_1_bias                  : 16    (32-bit unit)
    conv2d_2_weights               : 4608  (1-bit unit)
    conv2d_2_bias                  : 32    (32-bit unit)
    conv2d_3_weights               : 18432 (8-bit unit)
    conv2d_3_bias                  : 64    (32-bit unit)
    conv2d_4_weights               : 73728 (8-bit unit)
    conv2d_4_bias                  : 128   (32-bit unit)
    dense_1_weights                : 4096  (1-bit unit)
    dense_1_bias                   : 32    (1-bit unit)
    dense_2_weights                : 512   (1-bit unit)
    dense_2_bias                   : 16    (1-bit unit)

Weight sparsity:
... quantizing model
  normalization_1 has not been quantized
  batch_normalization_4 has not been quantized
  batch_normalization_5 has not been quantized
  batch_normalization_6 has not been quantized
  batch_normalization_7 has not been quantized
    conv2d_1                       : 0.7000
    conv2d_2                       : 0.0069
    conv2d_3                       : 0.1149
    conv2d_4                       : 0.1335
    dense_1                        : 0.0000
    dense_2                        : 0.0000
    ----------------------------------------
    Total Sparsity                 : 0.1191
