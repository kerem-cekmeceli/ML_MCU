Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 normalization (Normalizatio  (6191, 171, 13, 1)       3         
 n)                                                              
                                                                 
 conv2d_1 (QConv2D)          (6191, 171, 13, 16)       144       
                                                                 
 batch_normalization (BatchN  (6191, 171, 13, 16)      64        
 ormalization)                                                   
                                                                 
 act_1 (QActivation)         (6191, 171, 13, 16)       0         
                                                                 
 conv2d_2 (QConv2D)          (6191, 86, 7, 32)         4608      
                                                                 
 batch_normalization_1 (Batc  (6191, 86, 7, 32)        128       
 hNormalization)                                                 
                                                                 
 act_2 (QActivation)         (6191, 86, 7, 32)         0         
                                                                 
 max_pooling2d (MaxPooling2D  (6191, 43, 3, 32)        0         
 )                                                               
                                                                 
 conv2d_3 (QConv2D)          (6191, 22, 2, 64)         18432     
                                                                 
 batch_normalization_2 (Batc  (6191, 22, 2, 64)        256       
 hNormalization)                                                 
                                                                 
 act_3 (QActivation)         (6191, 22, 2, 64)         0         
                                                                 
 max_pooling2d_1 (MaxPooling  (6191, 11, 1, 64)        0         
 2D)                                                             
                                                                 
 conv2d_4 (QConv2D)          (6191, 6, 1, 128)         73728     
                                                                 
 batch_normalization_3 (Batc  (6191, 6, 1, 128)        512       
 hNormalization)                                                 
                                                                 
 act_4 (QActivation)         (6191, 6, 1, 128)         0         
                                                                 
 global_average_pooling2d (G  (6191, 128)              0         
 lobalAveragePooling2D)                                          
                                                                 
 flatten (Flatten)           (6191, 128)               0         
                                                                 
 dense_1 (QDense)            (6191, 32)                4128      
                                                                 
 act_5 (QActivation)         (6191, 32)                0         
                                                                 
 dense_2 (QDense)            (6191, 16)                528       
                                                                 
 softmax (Activation)        (6191, 16)                0         
                                                                 
=================================================================
Total params: 102,531
Trainable params: 102,048
Non-trainable params: 483
_________________________________________________________________

Number of operations in model:
    conv2d_1                      : 320112 (smult_8_8)
    conv2d_2                      : 2774016 (smux_1_2)
    conv2d_3                      : 811008 (smult_8_2)
    conv2d_4                      : 442368 (smult_8_2)
    dense_1                       : 4096  (smux_1_2)
    dense_2                       : 512   (smux_1_2)

Number of operation types in model:
    smult_8_2                     : 1253376
    smult_8_8                     : 320112
    smux_1_2                      : 2778624

Weight profiling:
    conv2d_1_weights               : 144   (8-bit unit)
    conv2d_1_bias                  : 0     (32-bit unit)
    conv2d_2_weights               : 4608  (1-bit unit)
    conv2d_2_bias                  : 0     (32-bit unit)
    conv2d_3_weights               : 18432 (8-bit unit)
    conv2d_3_bias                  : 0     (32-bit unit)
    conv2d_4_weights               : 73728 (8-bit unit)
    conv2d_4_bias                  : 0     (32-bit unit)
    dense_1_weights                : 4096  (1-bit unit)
    dense_1_bias                   : 32    (1-bit unit)
    dense_2_weights                : 512   (1-bit unit)
    dense_2_bias                   : 16    (1-bit unit)

Weight sparsity:
... quantizing model
  normalization has not been quantized
  batch_normalization has not been quantized
  batch_normalization_1 has not been quantized
  batch_normalization_2 has not been quantized
  batch_normalization_3 has not been quantized
    conv2d_1                       : 0.6319
    conv2d_2                       : 0.0000
    conv2d_3                       : 0.1097
    conv2d_4                       : 0.1345
    dense_1                        : 0.0000
    dense_2                        : 0.0000
    ----------------------------------------
    Total Sparsity                 : 0.1184
